site_date_starttime=site_date_starttime[!is.na(ActivityStartTime.Time),]
dim(site_date_starttime) # 1990 xx
# Check timeszones
site_date_starttime[,.N,by=ActivityStartTime.TimeZoneCode]
# Add datetime
site_date_starttime[,datetime:=as.POSIXct(paste(ActivityStartDate,ActivityStartTime.Time),format='%Y-%m-%d %H:%M:%S',tz='America/Denver')]
# Filter for minimum time value
site_date_starttime=site_date_starttime[,.(datetime=min(datetime)),by=.(MonitoringLocationIdentifier,ActivityStartDate)]
dim(site_date_starttime) # 1111 xx
# Add hour and minute
site_date_starttime[,hour:=hour(datetime)]
site_date_starttime[,minute:=minute(datetime)]
# Join unified time stamps back to data (by site & date)
intersect(names(ul_data),names(site_date_starttime))
ul_data=merge(ul_data,site_date_starttime,by=c('MonitoringLocationIdentifier','ActivityStartDate'),all.x=T) # Left outer join
dim(ul_data) # 50829 xx
# Subset to relevant columns
cols_keep=c(
'OrganizationIdentifier','OrganizationFormalName','MonitoringLocationIdentifier','MonitoringLocationName','MonitoringLocationTypeName',
'LatitudeMeasure','LongitudeMeasure','HorizontalCoordinateReferenceSystemDatumName',
# These are the columns that have been added through the code above
'SampleDepthUnit','SampleDepthValue','RelativeDepth','datetime','minute','hour',
'CharacteristicName','ResultSampleFractionText','ResultMeasureValue','ResultMeasure.MeasureUnitCode',
'MethodSpecificationName','MeasureQualifierCode','ResultDetectionConditionText',
'ResultStatusIdentifier','ResultValueTypeName','ActivityMediaName',
'EstimatedQuantitationLimit','LowerQuantitationLimit','LowerReportingLimit','MethodDetectionLevel',
'UpperQuantitationLimit','EstimatedQuantitationLimitUnit',
'LowerQuantitationLimitUnit','LowerReportingLimitUnit','MethodDetectionLevelUnit','UpperQuantitationLimitUnit'
)
ul_data=ul_data[,..cols_keep]
# Extracting unique result value for each site, date, depth, parameter, & fraction
ul_data=unique(ul_data)
dim(ul_data) # 47110 xx
# Check for multiple result values by site, date, depth, parameter, & fraction
tmp=ul_data[,.(MonitoringLocationIdentifier,datetime,SampleDepthValue,RelativeDepth,CharacteristicName,ResultSampleFractionText)]
dim(tmp) # 47110 xx
nrow(ul_data) - nrow(unique(tmp)) # 3568  # ">0" means there are not any multiple results
# Copy dataset and relevant fields
tmp=c('MonitoringLocationIdentifier','datetime','SampleDepthValue','RelativeDepth','CharacteristicName','ResultSampleFractionText')
result_count=copy(ul_data[,..tmp])
dim(result_count) # 47110 xx
# Count multiple results
result_count=result_count[,.(result_count=.N),by=tmp]
dim(result_count) # 43542 xx
View(result_count)
# Join result_count (use all fields)
ul_data=merge(ul_data,result_count,by=tmp,all.x=T) # Left outer join
dim(ul_data) # 47110 xx
ul_data[,.N,by=result_count]
# Sort
setorder(ul_data,MonitoringLocationIdentifier,datetime,SampleDepthValue,RelativeDepth,CharacteristicName,ResultSampleFractionText,ResultMeasureValue)
# Export to csv and RData
fwrite(ul_data,paste0('ul_data_wqp_processed_',Sys.Date(),'.csv'))
save(ul_data,file=paste0('ul_data_',Sys.Date(),'.RData'))
View(ul_data)
save.image()
wq_data=copy(ul_data)
library(data.table)
wq_data=copy(ul_data)
rm(ul_data)
library(wqTools)
library(data.table)
# detach(package:aaa,unload=T)
options(digits=5)
# Join activity metadata data to narrowresult xxx
intersect(names(ul_nr),names(ul_act))
wq_data=merge(ul_nr,ul_act,by='ActivityIdentifier',all.x=T) # Left outer join
dim(wq_data) # 54862 xx
# Join site data to narrowresult
intersect(names(wq_data),names(ul_sites))
wq_data=merge(wq_data,ul_sites,by='MonitoringLocationIdentifier',all.x=T) # Left outer join
# Join detection/quantification limit data to narrowresult
intersect(names(wq_data),names(ul_dql_wide))
wq_data=merge(wq_data,ul_dql_wide,by='ResultIdentifier',all.x=T) # Left outer join
# Remove QA/QC field replicate site
wq_data=wq_data[MonitoringLocationIdentifier!='UTAHDWQ_WQX-4917320',]
dim(wq_data) # 51405 xx
# Check field parameters for activity types
field_params=c('pH','Specific conductance','Dissolved oxygen (DO)','Dissolved oxygen saturation','Temperature,water')
wq_data[CharacteristicName %in% field_params,.N,by=ActivityTypeCode]
# Remove lab data for field parameters  # REVISIT. Why are "Sample-Routine" obs removed?
wq_data=wq_data[!(CharacteristicName %in% field_params &
ActivityTypeCode %in% c('Sample-Routine','Sample-Integrated Vertical Profile','Quality Control Sample-Field Replicate')),]
dim(wq_data) # 50829 xx
# (double) Check field parameters for activity types
wq_data[CharacteristicName %in% field_params,.N,by=ActivityTypeCode]
# Merge ActivityDepth and ResultDepth values to a new column
wq_data[,SampleDepthValue:=ActivityDepthHeightMeasure.MeasureValue] # Reset
wq_data[is.na(SampleDepthValue),SampleDepthValue:=ResultDepthHeightMeasure.MeasureValue]
# Merge ActivityDepth and ResultDepth units to a new column
wq_data[,SampleDepthUnit:=ActivityDepthHeightMeasure.MeasureUnitCode] # Reset
wq_data[is.na(SampleDepthUnit),SampleDepthUnit:=ResultDepthHeightMeasure.MeasureUnitCode]
# *NOTE:*
# Many records missing both depth fields have a RelativeDepth filled in which could potentially be used to fill in values.
# Others are for CharacteristicName == 'Depth, data-logger (ported)' and can be filled with the result value and unit.
wq_data[,.N,by=.(is.na(SampleDepthValue) & is.na(ActivityRelativeDepthName))]
#    is.na     N
# 1:  TRUE  5432
# 2: FALSE 45397
# knitr::kable(table(is.na(wq_data$SampleDepthValue) & is.na(wq_data$ActivityRelativeDepthName)))
wq_data[,.N,by=.(is.na(SampleDepthValue) & CharacteristicName=='Depth, data-logger (ported)')]
#    is.na     N
# 1: FALSE 50249
# 2:  TRUE   580
# knitr::kable(table(is.na(wq_data$SampleDepthValue) & wq_data$CharacteristicName=='Depth, data-logger (ported)'))
# Fill sample depths and units for CharacteristicName 'Depth, data-logger (ported)'
wq_data[is.na(SampleDepthValue) & CharacteristicName == 'Depth, data-logger (ported)',
SampleDepthValue:=ResultMeasureValue]
wq_data[is.na(SampleDepthUnit) & CharacteristicName == 'Depth, data-logger (ported)',
SampleDepthUnit:=ResultMeasure.MeasureUnitCode]
# Check SampleDepthValue
wq_data[,.N,by=.(is.na(SampleDepthValue) & CharacteristicName=='Depth, data-logger (ported)')]
#    is.na     N
# 1: FALSE 50829
# knitr::kable(table(is.na(wq_data$SampleDepthValue) & wq_data$CharacteristicName=='Depth, data-logger (ported)'))
# Setting SampleDepthValue to NA for records w/ ActivityRelativeDepthName=='Bottom' & ActivityDepthHeight==0
wq_data[ActivityRelativeDepthName=='Bottom' & ActivityDepthHeightMeasure.MeasureValue==0,SampleDepthValue:=NA]
# Generating new RelativeDepth column for cases where both ActivityDepth and ResultDepth are NULL
wq_data[,RelativeDepth:=NA_character_] # Reset
wq_data[is.na(SampleDepthValue) & !is.na(ActivityRelativeDepthName),RelativeDepth:=ActivityRelativeDepthName]
# Extract times by site & date
site_date_starttime=unique(wq_data[,.(MonitoringLocationIdentifier,ActivityStartDate,ActivityStartTime.Time,ActivityStartTime.TimeZoneCode)])
dim(site_date_starttime) # 2215 xx
# Remove Time=NA
site_date_starttime=site_date_starttime[!is.na(ActivityStartTime.Time),]
dim(site_date_starttime) # 1990 xx
# Check timeszones
site_date_starttime[,.N,by=ActivityStartTime.TimeZoneCode]
#    ActivityStartTime.TimeZoneCode    N
# 1:                            MDT   17
# 2:                            MST 1971
# 3:                            EST    2
# knitr::kable(table(site_date_starttime$ActivityStartTime.TimeZoneCode))
# *Note - a few samples marked as MDT time zone. Default seems to be MST. Accepting all times and setting tz to 'America/Denver'.*
# Add datetime
site_date_starttime[,datetime:=as.POSIXct(paste(ActivityStartDate,ActivityStartTime.Time),format='%Y-%m-%d %H:%M:%S',tz='America/Denver')]
# Filter for minimum time value
site_date_starttime=site_date_starttime[,.(datetime=min(datetime)),by=.(MonitoringLocationIdentifier,ActivityStartDate)]
dim(site_date_starttime) # 1111 xx
# Add hour and minute
site_date_starttime[,hour:=hour(datetime)]
site_date_starttime[,minute:=minute(datetime)]
# Join unified time stamps back to data (by site & date)
intersect(names(wq_data),names(site_date_starttime))
wq_data=merge(wq_data,site_date_starttime,by=c('MonitoringLocationIdentifier','ActivityStartDate'),all.x=T) # Left outer join
dim(wq_data) # 50829 xx
# Subset to relevant columns
cols_keep=c(
'OrganizationIdentifier','OrganizationFormalName','MonitoringLocationIdentifier','MonitoringLocationName','MonitoringLocationTypeName','LatitudeMeasure','LongitudeMeasure','HorizontalCoordinateReferenceSystemDatumName','DataLoggerLine',
# These are the columns that have been added through the code above
'SampleDepthUnit','SampleDepthValue','RelativeDepth','datetime','minute','hour',
'CharacteristicName','ResultSampleFractionText','ResultMeasureValue','ResultMeasure.MeasureUnitCode',
'MethodSpecificationName','MeasureQualifierCode','ResultDetectionConditionText',
'ResultStatusIdentifier','ResultValueTypeName','ActivityMediaName',
'EstimatedQuantitationLimit','LowerQuantitationLimit','LowerReportingLimit','MethodDetectionLevel',
'UpperQuantitationLimit','EstimatedQuantitationLimitUnit',
'LowerQuantitationLimitUnit','LowerReportingLimitUnit','MethodDetectionLevelUnit','UpperQuantitationLimitUnit'
)
wq_data=wq_data[,..cols_keep]
# Extracting unique result value for each site, date, depth, parameter, & fraction
wq_data=unique(wq_data)
dim(wq_data) # 47110 xx
dim(wq_data) # 47110 xx
?unique
# START HERE. "DataLoggerLine" is increasing this count. Is that a problem???
# Extracting unique result value for each site, date, depth, parameter, & fraction
a=unique(wq_data,by=c('MonitoringLocationIdentifier','datetime','SampleDepthValue','RelativeDepth','CharacteristicName','ResultSampleFractionText'))
dim(a) # 49418 xx  # WAS 47110 xx
# START HERE. "DataLoggerLine" is increasing this count. Is that a problem???
# Extracting unique result value for each site, date, depth, parameter, & fraction
wq_data=unique(wq_data) # REVISIT. ,by=c('MonitoringLocationIdentifier','datetime','SampleDepthValue','RelativeDepth','CharacteristicName','ResultSampleFractionText'))
dim(a) # 49418 xx  # WAS 47110 xx  # 43849 xx if I specify the
rm(a)
dim(wq_data) # 49418 xx  # WAS 47110 xx  # 43849 xx if I specify the
# Check for multiple result values by site, date, depth, parameter, & fraction
tmp=wq_data[,.(MonitoringLocationIdentifier,datetime,SampleDepthValue,RelativeDepth,CharacteristicName,ResultSampleFractionText)]
dim(tmp) # 47110 xx
nrow(wq_data) - nrow(unique(tmp)) # 3261  # ">0" means there ARE multiple results
# Copy dataset and relevant fields
tmp=c('MonitoringLocationIdentifier','datetime','SampleDepthValue','RelativeDepth','CharacteristicName','ResultSampleFractionText')
result_count=copy(wq_data[,..tmp])
dim(result_count) # 47110 xx
# Count multiple results
result_count=result_count[,.(result_count=.N),by=tmp]
dim(result_count) # 43849 xx
# Join result_count (use all fields)
wq_data=merge(wq_data,result_count,by=tmp,all.x=T) # Left outer join
dim(wq_data) # 47110 xx
wq_data[,.N,by=result_count]
# Sort
setorder(wq_data,MonitoringLocationIdentifier,datetime,SampleDepthValue,RelativeDepth,CharacteristicName,ResultSampleFractionText,ResultMeasureValue)
# Export to csv and RData
fwrite(wq_data,paste0('ArchivedProcessedDatasets/wq_data_wqp_processed_',Sys.Date(),'.csv'))
save(wq_data,file=paste0('ArchivedProcessedDatasets/wq_data_',Sys.Date(),'.RData'))
library(data.table)
# Join activity metadata data to narrowresult
intersect(names(ul_nr),names(ul_act))
wq_data=merge(ul_nr,ul_act,by='ActivityIdentifier',all.x=T) # Left outer join
dim(wq_data) # 54862 xx
intersect(names(wq_data),names(ul_sites))
wq_data=merge(wq_data,ul_sites,by='MonitoringLocationIdentifier',all.x=T) # Left outer join
# Join detection/quantification limit data to narrowresult
intersect(names(wq_data),names(ul_dql_wide))
wq_data=merge(wq_data,ul_dql_wide,by='ResultIdentifier',all.x=T) # Left outer join
# Write raw, as queried data from EPA WQP
fwrite(wq_data,paste0('ArchivedRawDatasets/ul_data_wqp_raw_',Sys.Date(),'.csv'))
dim(wq_data) # 54862 xx
###################################*
#### **** Process Raw Data **** ####
###################################*
###################################*
#### Filter Data ####
###################################*
# Remove QA/QC field replicate site
wq_data=wq_data[MonitoringLocationIdentifier!='UTAHDWQ_WQX-4917320',]
dim(wq_data) # 51405 xx
# Check field parameters for activity types
field_params=c('pH','Specific conductance','Dissolved oxygen (DO)','Dissolved oxygen saturation','Temperature,water')
wq_data[CharacteristicName %in% field_params,.N,by=ActivityTypeCode]
#                      ActivityTypeCode     N
# 1:                     Sample-Routine   412
# 2:                      Field Msr/Obs  3496
# 3: Field Msr/Obs-Portable Data Logger 12688
# 4: Sample-Integrated Vertical Profile   164
# knitr::kable(table(wq_data[CharacteristicName %in% field_params,'ActivityTypeCode']))
# Remove lab data for field parameters  # REVISIT. Why are "Sample-Routine" obs removed?
wq_data=wq_data[!(CharacteristicName %in% field_params &
ActivityTypeCode %in% c('Sample-Routine','Sample-Integrated Vertical Profile','Quality Control Sample-Field Replicate')),]
dim(wq_data) # 50829 xx
# (double) Check field parameters for activity types
wq_data[CharacteristicName %in% field_params,.N,by=ActivityTypeCode]
#                      ActivityTypeCode     N
# 1:                      Field Msr/Obs  3496
# 2: Field Msr/Obs-Portable Data Logger 12688
# knitr::kable(table(wq_data[CharacteristicName %in% field_params,'ActivityTypeCode']))
###################################*
#### Sample Depth ####
###################################*
# Merge ActivityDepth and ResultDepth values to a new column
wq_data[,SampleDepthValue:=ActivityDepthHeightMeasure.MeasureValue] # Reset
wq_data[is.na(SampleDepthValue),SampleDepthValue:=ResultDepthHeightMeasure.MeasureValue]
# Merge ActivityDepth and ResultDepth units to a new column
wq_data[,SampleDepthUnit:=ActivityDepthHeightMeasure.MeasureUnitCode] # Reset
wq_data[is.na(SampleDepthUnit),SampleDepthUnit:=ResultDepthHeightMeasure.MeasureUnitCode]
# *NOTE:*
# Many records missing both depth fields have a RelativeDepth filled in which could potentially be used to fill in values.
# Others are for CharacteristicName == 'Depth, data-logger (ported)' and can be filled with the result value and unit.
wq_data[,.N,by=.(is.na(SampleDepthValue) & is.na(ActivityRelativeDepthName))]
#    is.na     N
# 1:  TRUE  5432
# 2: FALSE 45397
# knitr::kable(table(is.na(wq_data$SampleDepthValue) & is.na(wq_data$ActivityRelativeDepthName)))
wq_data[,.N,by=.(is.na(SampleDepthValue) & CharacteristicName=='Depth, data-logger (ported)')]
#    is.na     N
# 1: FALSE 50249
# 2:  TRUE   580
# knitr::kable(table(is.na(wq_data$SampleDepthValue) & wq_data$CharacteristicName=='Depth, data-logger (ported)'))
# Fill sample depths and units for CharacteristicName 'Depth, data-logger (ported)'
wq_data[is.na(SampleDepthValue) & CharacteristicName == 'Depth, data-logger (ported)',
SampleDepthValue:=ResultMeasureValue]
wq_data[is.na(SampleDepthUnit) & CharacteristicName == 'Depth, data-logger (ported)',
SampleDepthUnit:=ResultMeasure.MeasureUnitCode]
# Check SampleDepthValue
wq_data[,.N,by=.(is.na(SampleDepthValue) & CharacteristicName=='Depth, data-logger (ported)')]
#    is.na     N
# 1: FALSE 50829
# knitr::kable(table(is.na(wq_data$SampleDepthValue) & wq_data$CharacteristicName=='Depth, data-logger (ported)'))
# Setting SampleDepthValue to NA for records w/ ActivityRelativeDepthName=='Bottom' & ActivityDepthHeight==0
wq_data[ActivityRelativeDepthName=='Bottom' & ActivityDepthHeightMeasure.MeasureValue==0,SampleDepthValue:=NA]
# Generating new RelativeDepth column for cases where both ActivityDepth and ResultDepth are NULL
wq_data[,RelativeDepth:=NA_character_] # Reset
wq_data[is.na(SampleDepthValue) & !is.na(ActivityRelativeDepthName),RelativeDepth:=ActivityRelativeDepthName]
###################################*
#### Add DateTime ####
###################################*
# Extract times by site & date
site_date_starttime=unique(wq_data[,.(MonitoringLocationIdentifier,ActivityStartDate,ActivityStartTime.Time,ActivityStartTime.TimeZoneCode)])
dim(site_date_starttime) # 2215 xx
# Remove Time=NA
site_date_starttime=site_date_starttime[!is.na(ActivityStartTime.Time),]
dim(site_date_starttime) # 1990 xx
# Check timeszones
site_date_starttime[,.N,by=ActivityStartTime.TimeZoneCode]
#    ActivityStartTime.TimeZoneCode    N
# 1:                            MDT   17
# 2:                            MST 1971
# 3:                            EST    2
# knitr::kable(table(site_date_starttime$ActivityStartTime.TimeZoneCode))
# *Note - a few samples marked as MDT time zone. Default seems to be MST. Accepting all times and setting tz to 'America/Denver'.*
# Add datetime
site_date_starttime[,datetime:=as.POSIXct(paste(ActivityStartDate,ActivityStartTime.Time),format='%Y-%m-%d %H:%M:%S',tz='America/Denver')]
# Filter for minimum time value
site_date_starttime=site_date_starttime[,.(datetime=min(datetime)),by=.(MonitoringLocationIdentifier,ActivityStartDate)]
dim(site_date_starttime) # 1111 xx
# Add hour and minute
site_date_starttime[,hour:=hour(datetime)]
site_date_starttime[,minute:=minute(datetime)]
# Join unified time stamps back to data (by site & date)
intersect(names(wq_data),names(site_date_starttime))
wq_data=merge(wq_data,site_date_starttime,by=c('MonitoringLocationIdentifier','ActivityStartDate'),all.x=T) # Left outer join
dim(wq_data) # 50829 xx
###################################*
#### Account for Multiple Results ####
###################################*
# Subset to relevant columns
cols_keep=c(
'OrganizationIdentifier','OrganizationFormalName','MonitoringLocationIdentifier','MonitoringLocationName','MonitoringLocationTypeName','LatitudeMeasure','LongitudeMeasure','HorizontalCoordinateReferenceSystemDatumName','ActivityStartDate','DataLoggerLine',
# These are the columns that have been added through the code above
'SampleDepthUnit','SampleDepthValue','RelativeDepth','datetime','minute','hour',
'CharacteristicName','ResultSampleFractionText','ResultMeasureValue','ResultMeasure.MeasureUnitCode',
'MethodSpecificationName','MeasureQualifierCode','ResultDetectionConditionText',
'ResultStatusIdentifier','ResultValueTypeName','ActivityMediaName',
'EstimatedQuantitationLimit','LowerQuantitationLimit','LowerReportingLimit','MethodDetectionLevel',
'UpperQuantitationLimit','EstimatedQuantitationLimitUnit',
'LowerQuantitationLimitUnit','LowerReportingLimitUnit','MethodDetectionLevelUnit','UpperQuantitationLimitUnit'
)
wq_data=wq_data[,..cols_keep]
# Extracting unique result value for each site, date, depth, parameter, & fraction
wq_data=unique(wq_data)
dim(wq_data) # 49418 xx
# Check for multiple result values by site, date, depth, parameter, & fraction
tmp=wq_data[,.(MonitoringLocationIdentifier,datetime,SampleDepthValue,RelativeDepth,CharacteristicName,ResultSampleFractionText)]
nrow(wq_data) - nrow(unique(tmp)) # 5569 - multiple results
# *NOTE:*
# Some records have one or more unique result value. These are flagged in processed data w/ result_count column.
# Copy dataset and relevant fields
tmp=c('MonitoringLocationIdentifier','datetime','SampleDepthValue','RelativeDepth','CharacteristicName','ResultSampleFractionText')
result_count=copy(wq_data[,..tmp])
dim(result_count) # 49418 xx
# Count multiple results
result_count=result_count[,.(result_count=.N),by=tmp]
dim(result_count) # 43849 xx
# Join result_count (use all fields)
wq_data=merge(wq_data,result_count,by=tmp,all.x=T) # Left outer join
dim(wq_data) # 49418 xx
wq_data[,.N,by=result_count]
# result_count     N
# 1:            1 40123
# 2:            2  5176
# 3:            3  1902
# 4:            4  1384
# 5:            5   695
# 6:            6    96
# 7:            9     9
# 8:           12    12
# 9:           21    21
# Sort
setorder(wq_data,MonitoringLocationIdentifier,datetime,SampleDepthValue,RelativeDepth,CharacteristicName,ResultSampleFractionText,ResultMeasureValue)
# Export to csv and RData
fwrite(wq_data,paste0('ArchivedProcessedDatasets/wq_data_wqp_processed_',Sys.Date(),'.csv'))
save(wq_data,file=paste0('ArchivedProcessedDatasets/wq_data_',Sys.Date(),'.RData'))
wq_data[,.N,by=result_count]
# TRY
sum(is.na(wq_data$ActivityStartDate)) # 0
head(wq_data$ActivityStartDate)
wq_data=merge(ul_nr,ul_act,by='ActivityIdentifier',all.x=T) # Left outer join
dim(wq_data) # 54862 xx
# Convert to Date
wq_data[,ActivityStartDate:=as.Date(ActivityStartDate,format='%Y-%m-%d')]
head(wq_data$ActivityStartDate)
intersect(names(wq_data),names(ul_sites))
wq_data=merge(wq_data,ul_sites,by='MonitoringLocationIdentifier',all.x=T) # Left outer join
# Join detection/quantification limit data to narrowresult
intersect(names(wq_data),names(ul_dql_wide))
wq_data=merge(wq_data,ul_dql_wide,by='ResultIdentifier',all.x=T) # Left outer join
# Write raw, as queried data from EPA WQP
fwrite(wq_data,paste0('ArchivedRawDatasets/ul_data_wqp_raw_',Sys.Date(),'.csv'))
dim(wq_data) # 54862 xx
###################################*
#### **** Process Raw Data **** ####
###################################*
###################################*
#### Filter Data ####
###################################*
# Remove QA/QC field replicate site
wq_data=wq_data[MonitoringLocationIdentifier!='UTAHDWQ_WQX-4917320',]
dim(wq_data) # 51405 xx
# Check field parameters for activity types
field_params=c('pH','Specific conductance','Dissolved oxygen (DO)','Dissolved oxygen saturation','Temperature,water')
wq_data[CharacteristicName %in% field_params,.N,by=ActivityTypeCode]
#                      ActivityTypeCode     N
# 1:                     Sample-Routine   412
# 2:                      Field Msr/Obs  3496
# 3: Field Msr/Obs-Portable Data Logger 12688
# 4: Sample-Integrated Vertical Profile   164
# knitr::kable(table(wq_data[CharacteristicName %in% field_params,'ActivityTypeCode']))
# Remove lab data for field parameters  # REVISIT. Why are "Sample-Routine" obs removed?
wq_data=wq_data[!(CharacteristicName %in% field_params &
ActivityTypeCode %in% c('Sample-Routine','Sample-Integrated Vertical Profile','Quality Control Sample-Field Replicate')),]
dim(wq_data) # 50829 xx
# (double) Check field parameters for activity types
wq_data[CharacteristicName %in% field_params,.N,by=ActivityTypeCode]
#                      ActivityTypeCode     N
# 1:                      Field Msr/Obs  3496
# 2: Field Msr/Obs-Portable Data Logger 12688
# knitr::kable(table(wq_data[CharacteristicName %in% field_params,'ActivityTypeCode']))
###################################*
#### Sample Depth ####
###################################*
# Merge ActivityDepth and ResultDepth values to a new column
wq_data[,SampleDepthValue:=ActivityDepthHeightMeasure.MeasureValue] # Reset
wq_data[is.na(SampleDepthValue),SampleDepthValue:=ResultDepthHeightMeasure.MeasureValue]
# Merge ActivityDepth and ResultDepth units to a new column
wq_data[,SampleDepthUnit:=ActivityDepthHeightMeasure.MeasureUnitCode] # Reset
wq_data[is.na(SampleDepthUnit),SampleDepthUnit:=ResultDepthHeightMeasure.MeasureUnitCode]
# *NOTE:*
# Many records missing both depth fields have a RelativeDepth filled in which could potentially be used to fill in values.
# Others are for CharacteristicName == 'Depth, data-logger (ported)' and can be filled with the result value and unit.
wq_data[,.N,by=.(is.na(SampleDepthValue) & is.na(ActivityRelativeDepthName))]
#    is.na     N
# 1:  TRUE  5432
# 2: FALSE 45397
# knitr::kable(table(is.na(wq_data$SampleDepthValue) & is.na(wq_data$ActivityRelativeDepthName)))
wq_data[,.N,by=.(is.na(SampleDepthValue) & CharacteristicName=='Depth, data-logger (ported)')]
#    is.na     N
# 1: FALSE 50249
# 2:  TRUE   580
# knitr::kable(table(is.na(wq_data$SampleDepthValue) & wq_data$CharacteristicName=='Depth, data-logger (ported)'))
# Fill sample depths and units for CharacteristicName 'Depth, data-logger (ported)'
wq_data[is.na(SampleDepthValue) & CharacteristicName == 'Depth, data-logger (ported)',
SampleDepthValue:=ResultMeasureValue]
wq_data[is.na(SampleDepthUnit) & CharacteristicName == 'Depth, data-logger (ported)',
SampleDepthUnit:=ResultMeasure.MeasureUnitCode]
# Check SampleDepthValue
wq_data[,.N,by=.(is.na(SampleDepthValue) & CharacteristicName=='Depth, data-logger (ported)')]
#    is.na     N
# 1: FALSE 50829
# knitr::kable(table(is.na(wq_data$SampleDepthValue) & wq_data$CharacteristicName=='Depth, data-logger (ported)'))
# Setting SampleDepthValue to NA for records w/ ActivityRelativeDepthName=='Bottom' & ActivityDepthHeight==0
wq_data[ActivityRelativeDepthName=='Bottom' & ActivityDepthHeightMeasure.MeasureValue==0,SampleDepthValue:=NA]
# Generating new RelativeDepth column for cases where both ActivityDepth and ResultDepth are NULL
wq_data[,RelativeDepth:=NA_character_] # Reset
wq_data[is.na(SampleDepthValue) & !is.na(ActivityRelativeDepthName),RelativeDepth:=ActivityRelativeDepthName]
###################################*
#### Add DateTime ####
###################################*
# Extract times by site & date
site_date_starttime=unique(wq_data[,.(MonitoringLocationIdentifier,ActivityStartDate,ActivityStartTime.Time,ActivityStartTime.TimeZoneCode)])
dim(site_date_starttime) # 2215 xx
# Remove Time=NA
site_date_starttime=site_date_starttime[!is.na(ActivityStartTime.Time),]
dim(site_date_starttime) # 1990 xx
# Check timeszones
site_date_starttime[,.N,by=ActivityStartTime.TimeZoneCode]
#    ActivityStartTime.TimeZoneCode    N
# 1:                            MDT   17
# 2:                            MST 1971
# 3:                            EST    2
# knitr::kable(table(site_date_starttime$ActivityStartTime.TimeZoneCode))
# *Note - a few samples marked as MDT time zone. Default seems to be MST. Accepting all times and setting tz to 'America/Denver'.*
# Add datetime
site_date_starttime[,datetime:=as.POSIXct(paste(ActivityStartDate,ActivityStartTime.Time),format='%Y-%m-%d %H:%M:%S',tz='America/Denver')]
# Filter for minimum time value
site_date_starttime=site_date_starttime[,.(datetime=min(datetime)),by=.(MonitoringLocationIdentifier,ActivityStartDate)]
dim(site_date_starttime) # 1111 xx
# Add hour and minute
site_date_starttime[,hour:=hour(datetime)]
site_date_starttime[,minute:=minute(datetime)]
# Join unified time stamps back to data (by site & date)
intersect(names(wq_data),names(site_date_starttime))
wq_data=merge(wq_data,site_date_starttime,by=c('MonitoringLocationIdentifier','ActivityStartDate'),all.x=T) # Left outer join
dim(wq_data) # 50829 xx
###################################*
#### Account for Multiple Results ####
###################################*
# Subset to relevant columns
cols_keep=c(
'OrganizationIdentifier','OrganizationFormalName','MonitoringLocationIdentifier','MonitoringLocationName','MonitoringLocationTypeName','LatitudeMeasure','LongitudeMeasure','HorizontalCoordinateReferenceSystemDatumName','ActivityStartDate','DataLoggerLine',
# These are the columns that have been added through the code above
'SampleDepthUnit','SampleDepthValue','RelativeDepth','datetime','minute','hour',
'CharacteristicName','ResultSampleFractionText','ResultMeasureValue','ResultMeasure.MeasureUnitCode',
'MethodSpecificationName','MeasureQualifierCode','ResultDetectionConditionText',
'ResultStatusIdentifier','ResultValueTypeName','ActivityMediaName',
'EstimatedQuantitationLimit','LowerQuantitationLimit','LowerReportingLimit','MethodDetectionLevel',
'UpperQuantitationLimit','EstimatedQuantitationLimitUnit',
'LowerQuantitationLimitUnit','LowerReportingLimitUnit','MethodDetectionLevelUnit','UpperQuantitationLimitUnit'
)
wq_data=wq_data[,..cols_keep]
# Extracting unique result value for each site, date, depth, parameter, & fraction
wq_data=unique(wq_data)
dim(wq_data) # 49418 xx
# Check for multiple result values by site, date, depth, parameter, & fraction
tmp=wq_data[,.(MonitoringLocationIdentifier,datetime,SampleDepthValue,RelativeDepth,CharacteristicName,ResultSampleFractionText)]
nrow(wq_data) - nrow(unique(tmp)) # 5569 - multiple results
# *NOTE:*
# Some records have one or more unique result value. These are flagged in processed data w/ result_count column.
# Copy dataset and relevant fields
tmp=c('MonitoringLocationIdentifier','datetime','SampleDepthValue','RelativeDepth','CharacteristicName','ResultSampleFractionText')
result_count=copy(wq_data[,..tmp])
dim(result_count) # 49418 xx
# Count multiple results
result_count=result_count[,.(result_count=.N),by=tmp]
dim(result_count) # 43849 xx
# Join result_count (use all fields)
wq_data=merge(wq_data,result_count,by=tmp,all.x=T) # Left outer join
dim(wq_data) # 49422 xx
wq_data[,.N,by=result_count]
#    result_count     N
# 1:            1 40123
# 2:            2  5176
# 3:            3  1902
# 4:            4  1384
# 5:            5   695
# 6:            6    96
# 7:           13    13
# 8:           12    12
# 9:           21    21
# Sort
setorder(wq_data,MonitoringLocationIdentifier,datetime,SampleDepthValue,RelativeDepth,CharacteristicName,ResultSampleFractionText,ResultMeasureValue)
# Export to csv and RData
fwrite(wq_data,paste0('ArchivedProcessedDatasets/wq_data_wqp_processed_',Sys.Date(),'.csv'))
save(wq_data,file=paste0('ArchivedProcessedDatasets/wq_data_',Sys.Date(),'.RData'))
